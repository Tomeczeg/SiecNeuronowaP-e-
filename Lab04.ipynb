{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab04.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPKxJ8+6EO3Z3jvodnd+ttS"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"qaNowI2VfSeW","colab_type":"code","outputId":"6bbc71da-2f2a-4c2f-d79b-df3fb852ec06","executionInfo":{"status":"ok","timestamp":1588580758333,"user_tz":-120,"elapsed":20538,"user":{"displayName":"Tom Kań","photoUrl":"","userId":"17832087581577314826"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive\n","%cd '/gdrive/My Drive/Colab Notebooks/baza'\n","\n","!pip show tensorflow\n","\n","!pip show keras\n","\n","# For the current version: \n","#!pip install --upgrade tensorflow\n","\n","# For a specific version:\n","!pip install tensorflow==1.14\n","\n","!pip install keras==2.2.4\n","\n","#Bibioteki do obliczen tensorowych\n","import tensorflow as tf\n","from tensorflow import keras\n","#import plaidml.keras\n","#plaidml.keras.install_backend()\n","\n","#Bibioteka do obsługi sieci neuronowych\n","import keras\n","\n","\n","#Załadowania bazy uczącej\n","import imageio\n","import numpy as np\n","\n","import os\n","\n","from keras.models import load_model\n","\n","# returns a compiled model\n","# identical to the previous one\n","genderModel = load_model('siec.h5')\n","genderModel.summary() # Display summary\n","\n","ImgCount = 50\n","ImgWidth = 100\n","ImgHeight = 100\n","realwoman=0\n","realman=0\n","womanasman=0\n","manaswoman=0\n","\n","BazaImg = np.empty((50,ImgHeight,ImgWidth,3))\n","dirList = os.listdir(\"baza_testowa//K\")\n","i=0\n","for dir in dirList:\n","  print(\"k\", dir)\n","  FileName = \"baza_testowa//K//{}\".format(dir)\n","  Img = imageio.imread(FileName)\n","  Img = (Img / 127.5) - 1\n","  BazaImg[i,:,:,:] = Img[0:ImgHeight,0:ImgWidth,0:3]\n","  i=i+1\n","  if i>=ImgCount/2:\n","    break\n","\n","dirList = os.listdir(\"baza_testowa//M\")\n","for dir in dirList:\n","  print(\"m\", dir)\n","  FileName = \"baza_testowa//M//{}\".format(dir)\n","  Img = imageio.imread(FileName)\n","  Img = (Img / 127.5) - 1\n","  BazaImg[i,:,:,:] = Img[0:ImgHeight,0:ImgWidth,0:3]\n","  i=i+1\n","  if i>=ImgCount:\n","    break\n","\n","gender = genderModel.predict(BazaImg) # 0 - m, 1 - k\n","print(gender)\n","for j in range(ImgCount):\n","  if(j<ImgCount/2):\n","    if(gender[j]>=0.5):\n","      realwoman=realwoman+1\n","    else:\n","      womanasman=womanasman+1\n","  else:\n","    if(gender[j]<0.5):\n","      realman=realman+1\n","    else:\n","      manaswoman=manaswoman+1\n","\n","print(\"liczba kobiet zaklasyfikowanych jako kobiety\", realwoman)\n","print(\"liczba kobiet zaklasyfikowanych jako mezczyzni\", womanasman)\n","print(\"liczba mezczyzn zaklasyfikowanych jako mezczyzni\", realman)\n","print(\"liczba mezczyzn zaklasyfikowanych jako kobiety\", fakewoman)\n","tekst=open('wynik_sieci.txt', 'w')\n","tekst.write(\"+-----------------------+----------------------+\\n\")\n","tekst.write(\"|                       | Faktyczna płeć osoby |\\n\")\n","tekst.write(\"|                       | na zdjęciu           |\\n\")\n","tekst.write(\"+                       +----------+-----------+\\n\")\n","tekst.write(\"|                       |  Kobieta | Mężczyzna |\\n\")\n","tekst.write(\"+-----------+-----------+----------+-----------+\\n\")\n","tekst.write(\"| Odpowiedź |  Kobieta  |    \"+ str(realwoman)+\"    |     \"+str(manaswoman)+\"    |\\n\")\n","tekst.write(\"| sieci     +-----------+----------+-----------+\\n\")\n","tekst.write(\"|           | Mężczyzna |     \"+str(womanasman)+\"    |     \"+str(realman)+\"    |\\n\")\n","tekst.write(\"+-----------+-----------+----------+-----------+\\n\")\n","tekst.close()\n","#50\n","#--------------------------------\n","# Prawdziwa Płeć | Odpowiedz sieci\n","#----------------+---------+------\n","#                |   M     |  K\n","#----------------+---------+------\n","#   M            |         |  1\n","#----------------+---------+------\n","#   K            |         |  1\n","\n","#ImgCount = 100\n","#ImgWidth = 100\n","#ImgHeight = 100\n","#\n","#BazaImg = np.empty((ImgCount,ImgHeight,ImgWidth,3))\n","#BazaAns = np.empty((ImgCount)) # 0 - m, 1 - k\n","#dirList = os.listdir(\".\\\\baza\\\\m\")\n","#i=0\n","#for dir in dirList:\n","#  print(dir)\n","#  FileName = \".\\\\baza\\\\m\\\\{}\".format(dir)\n","#  Img = imageio.imread(FileName)\n","#  Img = (Img / 127.5) - 1\n","#  BazaImg[i,:,:,:] = Img[0:ImgHeight,0:ImgWidth,0:3]\n","#  BazaAns[i] = 0\n","#  i=i+1\n","#  if i>=ImgCount/2:\n","#    break\n","#\n","#dirList = os.listdir(\".\\\\baza\\\\k\")\n","#for dir in dirList:\n","#  print(dir)\n","#  FileName = \".\\\\baza\\\\k\\\\{}\".format(dir)\n","#  Img = imageio.imread(FileName)\n","#  Img = (Img / 127.5) - 1\n","#  BazaImg[i,:,:,:] = Img[0:ImgHeight,0:ImgWidth,0:3]\n","#  BazaAns[i] = 1\n","#  i=i+1\n","#  if i>=ImgCount:\n","#    break\n","#\n","#BazaImg = BazaImg[0:i,:,:,:]\n","#BazaAns = BazaAns[0:i]\n","#print(BazaImg.shape)\n","#\n","##Stworzenia modelu sieci\n","#\n","#input  = keras.engine.input_layer.Input(shape=(ImgHeight,ImgWidth,3),name=\"wejscie\")\n","#\n","#FlattenLayer = keras.layers.Flatten()\n","#\n","#path = FlattenLayer(input)\n","#\n","#for i in range(0,6):\n","#  LayerDense1 = keras.layers.Dense(50, activation=None, use_bias=True, kernel_initializer='glorot_uniform')\n","#  path = LayerDense1(path)\n","#\n","#  LayerPReLU1 = keras.layers.PReLU(alpha_initializer='zeros', shared_axes=None)\n","#  path = LayerPReLU1(path)\n","#\n","#LayerDenseN = keras.layers.Dense(1, activation=keras.activations.sigmoid, use_bias=True, kernel_initializer='glorot_uniform')\n","#output = LayerDenseN(path)\n","#\n","##---------------------------------\n","## Creation of TensorFlow Model\n","##---------------------------------\n","#genderModel = keras.Model(input, output, name='genderEstimatior')\n","#\n","#genderModel.summary() # Display summary\n","#\n","##Włączenia procesu uczenia\n","#\n","#rmsOptimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n","#\n","#genderModel.compile(optimizer=rmsOptimizer,loss=keras.losses.binary_crossentropy,metrics=['accuracy'])\n","#\n","#genderModel.fit(BazaImg, BazaAns, epochs=15, batch_size=10, shuffle=True)\n","#\n","#genderModel.save('siec.h5')\n","##Przetestować / użyć sieci\n","#\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n","/gdrive\n","/gdrive/My Drive/Colab Notebooks/baza\n","Name: tensorflow\n","Version: 1.14.0\n","Summary: TensorFlow is an open source machine learning framework for everyone.\n","Home-page: https://www.tensorflow.org/\n","Author: Google Inc.\n","Author-email: packages@tensorflow.org\n","License: Apache 2.0\n","Location: /usr/local/lib/python3.6/dist-packages\n","Requires: tensorflow-estimator, gast, wrapt, six, wheel, tensorboard, numpy, termcolor, keras-applications, keras-preprocessing, astor, absl-py, protobuf, grpcio, google-pasta\n","Required-by: fancyimpute\n","Name: Keras\n","Version: 2.2.4\n","Summary: Deep Learning for humans\n","Home-page: https://github.com/keras-team/keras\n","Author: Francois Chollet\n","Author-email: francois.chollet@gmail.com\n","License: MIT\n","Location: /usr/local/lib/python3.6/dist-packages\n","Requires: six, h5py, keras-preprocessing, scipy, pyyaml, keras-applications, numpy\n","Required-by: textgenrnn, keras-vis, kapre, fancyimpute\n","Requirement already satisfied: tensorflow==1.14 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n","Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n","Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.3)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.28.1)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (46.1.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.1)\n","Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (2.2.4)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.3)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","wejscie (InputLayer)         (None, 100, 100, 3)       0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 30000)             0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 50)                1500050   \n","_________________________________________________________________\n","p_re_lu_1 (PReLU)            (None, 50)                50        \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 50)                2550      \n","_________________________________________________________________\n","p_re_lu_2 (PReLU)            (None, 50)                50        \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 50)                2550      \n","_________________________________________________________________\n","p_re_lu_3 (PReLU)            (None, 50)                50        \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 50)                2550      \n","_________________________________________________________________\n","p_re_lu_4 (PReLU)            (None, 50)                50        \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 50)                2550      \n","_________________________________________________________________\n","p_re_lu_5 (PReLU)            (None, 50)                50        \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 50)                2550      \n","_________________________________________________________________\n","p_re_lu_6 (PReLU)            (None, 50)                50        \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 1)                 51        \n","=================================================================\n","Total params: 1,513,151\n","Trainable params: 1,513,151\n","Non-trainable params: 0\n","_________________________________________________________________\n","k 2.jpg\n","k 5.jpg\n","k 6.jpg\n","k 7.jpg\n","k 8.jpg\n","k 12.jpg\n","k 11.jpg\n","k 13.jpg\n","k 14.jpg\n","k 15.jpg\n","k 1.jpg\n","k 3.jpg\n","k 4.jpg\n","k 22.jpg\n","k 23.jpg\n","k 24.jpg\n","k 25.jpg\n","k 21.jpg\n","k 16.jpg\n","k 17.jpg\n","k 18.jpg\n","k 19.jpg\n","k 20.jpg\n","k 26.jpg\n","k 27.jpg\n","m 3.jpg\n","m 4.jpg\n","m 5.jpg\n","m 6.jpg\n","m 7.jpg\n","m 8.jpg\n","m 9.jpg\n","m 10.jpg\n","m 11.jpg\n","m 12.jpg\n","m 17.jpg\n","m 23.jpg\n","m 24.jpg\n","m 16.jpg\n","m 25.jpg\n","m 21.jpg\n","m 20.jpg\n","m 19.jpg\n","m 18.jpg\n","m 2.jpg\n","m 1.jpg\n","m 15.jpg\n","m 14.jpg\n","m 22.jpg\n","m 13.jpg\n","[[1.24573708e-05]\n"," [2.54929066e-04]\n"," [9.98238206e-01]\n"," [0.00000000e+00]\n"," [0.00000000e+00]\n"," [0.00000000e+00]\n"," [0.00000000e+00]\n"," [9.98173475e-01]\n"," [9.99023676e-01]\n"," [0.00000000e+00]\n"," [7.45684683e-01]\n"," [1.00000000e+00]\n"," [1.00000000e+00]\n"," [9.99450684e-04]\n"," [9.99999762e-01]\n"," [1.00000000e+00]\n"," [1.32620335e-05]\n"," [9.99962687e-01]\n"," [9.99999762e-01]\n"," [9.99998748e-01]\n"," [1.00000000e+00]\n"," [0.00000000e+00]\n"," [0.00000000e+00]\n"," [9.12626863e-01]\n"," [0.00000000e+00]\n"," [2.33650208e-05]\n"," [2.53319740e-06]\n"," [0.00000000e+00]\n"," [5.52982092e-03]\n"," [9.99672532e-01]\n"," [0.00000000e+00]\n"," [2.68220901e-07]\n"," [0.00000000e+00]\n"," [0.00000000e+00]\n"," [6.21914864e-04]\n"," [9.99995947e-01]\n"," [2.87795067e-03]\n"," [1.22189522e-06]\n"," [8.64267349e-07]\n"," [2.98023224e-08]\n"," [5.17481506e-01]\n"," [8.22246075e-04]\n"," [2.98023224e-08]\n"," [3.87430191e-07]\n"," [0.00000000e+00]\n"," [2.20119953e-03]\n"," [7.10934401e-04]\n"," [9.98052716e-01]\n"," [3.04162813e-06]\n"," [4.23346698e-01]]\n","liczba kobiet zaklasyfikowanych jako kobiety 13\n","liczba kobiet zaklasyfikowanych jako mezczyzni 12\n","liczba mezczyzn zaklasyfikowanych jako mezczyzni 21\n","liczba mezczyzn zaklasyfikowanych jako kobiety 4\n"],"name":"stdout"}]}]}